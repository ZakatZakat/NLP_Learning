GPT_config_124M = {
    'vocab_size': 50257,
    'context_length': 1024,
    'num_head': 12, 
    'emb_dim': 768,
    'n_layers': 12, 
    'dropout': 0.1,
    'qkv_bias': False
}