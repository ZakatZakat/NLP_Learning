{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oskar/nlll/NLP_Learning/.venv/lib64/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('/home/oskar/nlll/NLP_Learning/NLP_Learning')\n",
    "\n",
    "from module import *\n",
    "from functions import *\n",
    "from dataloader import *\n",
    "from preprocessing import *\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_config_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"num_head\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"dropout\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_config_124M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = read_csv_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "test_data = text_data[split_idx:]\n",
    "\n",
    "train_dataloader = create_dataloader(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length = GPT_config_124M[\"context_length\"],\n",
    "    stride = GPT_config_124M[\"context_length\"],\n",
    "    shuffle = True,\n",
    "    drop_last = True,\n",
    "    num_workers = 0\n",
    ")\n",
    "\n",
    "val_dataloader = create_dataloader(\n",
    "    test_data,\n",
    "    batch_size=2,\n",
    "    max_length = GPT_config_124M[\"context_length\"],\n",
    "    stride = GPT_config_124M[\"context_length\"],\n",
    "    shuffle = False,\n",
    "    drop_last = False,\n",
    "    num_workers = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.973967658148872\n",
      "Validation loss: 10.948689460754395\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "train_loss = calc_loss_loader(train_dataloader, model, device)\n",
    "val_loss = calc_loss_loader(val_dataloader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, \n",
    "                       eval_freq, eval_iter, start_context):\n",
    "    train_loss, val_loss, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss_val, val_loss_val = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_loss.append(train_loss_val)\n",
    "                val_loss.append(val_loss_val)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(\"Epoch\", epoch, \"Step\", global_step, \"Train loss\", train_loss[-1], \"Val loss\", val_loss[-1])\n",
    "\n",
    "        generate_and_print_sample(model, train_loader.dataset.tokenizer, device, start_context, eval_iter)\n",
    "    return train_loss, val_loss, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context, eval_iter):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(model, encoded, eval_iter, context_size)\n",
    "        decoded_text = token_to_text(token_ids, tokenizer)\n",
    "        print(decoded_text.replace('\\n', ' '))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Step 0 Train loss 10.642916997273764 Val loss 10.659255027770996\n",
      "Epoch 0 Step 5 Train loss 9.47816605038113 Val loss 9.640358924865723\n",
      "Every effort moves you,, the,,\n",
      "Epoch 1 Step 10 Train loss 8.863042407565647 Val loss 9.071943283081055\n",
      "Epoch 1 Step 15 Train loss 8.434476322597927 Val loss 8.653169631958008\n",
      "Every effort moves you,, the,,\n",
      "Epoch 2 Step 20 Train loss 8.017120944129097 Val loss 8.230504989624023\n",
      "Epoch 2 Step 25 Train loss 7.684959676530626 Val loss 7.881529808044434\n",
      "Every effort moves you the, the, the\n",
      "Epoch 3 Step 30 Train loss 7.470898840162489 Val loss 7.666396617889404\n",
      "Epoch 3 Step 35 Train loss 7.302070246802436 Val loss 7.504195690155029\n",
      "Every effort moves you the, the, the\n",
      "Epoch 4 Step 40 Train loss 7.173399024539524 Val loss 7.383875370025635\n",
      "Every effort moves you,, and,,\n",
      "Epoch 5 Step 45 Train loss 7.06577385796441 Val loss 7.2563066482543945\n",
      "Epoch 5 Step 50 Train loss 6.977528889973958 Val loss 7.190995693206787\n",
      "Every effort moves you, the   \n",
      "Epoch 6 Step 55 Train loss 6.9085827933417425 Val loss 7.15108060836792\n",
      "Epoch 6 Step 60 Train loss 6.83456293741862 Val loss 7.099959373474121\n",
      "Every effort moves you,, and, the\n",
      "Epoch 7 Step 65 Train loss 6.7739308675130205 Val loss 7.01814079284668\n",
      "Epoch 7 Step 70 Train loss 6.730337884691027 Val loss 6.987751007080078\n",
      "Every effort moves you, and, and,\n",
      "Epoch 8 Step 75 Train loss 6.682162231869167 Val loss 6.968149662017822\n",
      "Epoch 8 Step 80 Train loss 6.64085594813029 Val loss 6.927315711975098\n",
      "Every effort moves you, the, the,\n",
      "Epoch 9 Step 85 Train loss 6.607117282019721 Val loss 6.925051689147949\n",
      "Every effort moves you, and I, and\n",
      "Epoch 10 Step 90 Train loss 6.57154999838935 Val loss 6.892611026763916\n",
      "Epoch 10 Step 95 Train loss 6.546641084882948 Val loss 6.873459815979004\n",
      "Every effort moves you, and, and,\n",
      "Epoch 11 Step 100 Train loss 6.522914674546984 Val loss 6.869065284729004\n",
      "Epoch 11 Step 105 Train loss 6.492209752400716 Val loss 6.839035987854004\n",
      "Every effort moves you, and, and,\n",
      "Epoch 12 Step 110 Train loss 6.475679185655382 Val loss 6.831901550292969\n",
      "Epoch 12 Step 115 Train loss 6.4497043821546765 Val loss 6.85872220993042\n",
      "Every effort moves you, and I had \n",
      "Epoch 13 Step 120 Train loss 6.435597790612115 Val loss 6.820849895477295\n",
      "Epoch 13 Step 125 Train loss 6.414171271853977 Val loss 6.847984790802002\n",
      "Every effort moves you, and, and,\n",
      "Epoch 14 Step 130 Train loss 6.401531802283393 Val loss 6.8158769607543945\n",
      "Every effort moves you, and I, and\n",
      "Epoch 15 Step 135 Train loss 6.3825638559129505 Val loss 6.8126749992370605\n",
      "Epoch 15 Step 140 Train loss 6.373226854536268 Val loss 6.819595813751221\n",
      "Every effort moves you, and, and,\n",
      "Epoch 16 Step 145 Train loss 6.360598564147949 Val loss 6.809051036834717\n",
      "Epoch 16 Step 150 Train loss 6.351041952768962 Val loss 6.78619909286499\n",
      "Every effort moves you, and I had the\n",
      "Epoch 17 Step 155 Train loss 6.3481615914238825 Val loss 6.772096633911133\n",
      "Epoch 17 Step 160 Train loss 6.3360509342617455 Val loss 6.790340900421143\n",
      "Every effort moves you, and, and,\n",
      "Epoch 18 Step 165 Train loss 6.326008001963298 Val loss 6.777473449707031\n",
      "Epoch 18 Step 170 Train loss 6.317774242824978 Val loss 6.7655253410339355\n",
      "Every effort moves you.    \n",
      "Epoch 19 Step 175 Train loss 6.314305782318115 Val loss 6.779040336608887\n",
      "Every effort moves you, and, and,\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_config_124M)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "num_epochs = 20\n",
    "\n",
    "train_loss, val_loss, tokens_seen = train_model_simple(\n",
    "    model, train_dataloader, val_dataloader, optimizer,\n",
    "    device, eval_freq=5, eval_iter=5, start_context=\"Every effort moves you\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dasfdsaf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdasfdsaf\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dasfdsaf' is not defined"
     ]
    }
   ],
   "source": [
    "dasfdsaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument 'tokens': 'list' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m tiktoken\u001b[38;5;241m.\u001b[39mget_encoding(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m6109\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3626\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m345\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m262\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/nlll/NLP_Learning/.venv/lib64/python3.12/site-packages/tiktoken/core.py:258\u001b[0m, in \u001b[0;36mEncoding.decode\u001b[0;34m(self, tokens, errors)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokens: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m], errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    247\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Decodes a list of tokens into a string.\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m    WARNING: the default behaviour of this function is lossy, since decoded bytes are not\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_core_bpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m, errors\u001b[38;5;241m=\u001b[39merrors)\n",
      "\u001b[0;31mTypeError\u001b[0m: argument 'tokens': 'list' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "tokenizer.decode(torch.tensor([[6109, 3626, 6100,  345,  262]]).unsqueeze(0).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you the\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "\n",
    "# Get the tokenizer for \"gpt2\" encoding\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# Create a tensor for the tokens\n",
    "token_tensor = torch.tensor([6109, 3626, 6100, 345, 262])\n",
    "\n",
    "# Decode the token ids directly from a flat list (converted from tensor to list)\n",
    "decoded_text = tokenizer.decode(token_tensor.tolist())\n",
    "\n",
    "print(decoded_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
