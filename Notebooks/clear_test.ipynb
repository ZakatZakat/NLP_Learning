{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/askarembulatov/Github_projects/NLP_task/NLP/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "sys.path.append('/Users/askarembulatov/Github_projects/NLP_task/NLP/NLP_Learning')\n",
    "\n",
    "from module import *\n",
    "from functions import *\n",
    "from dataloader import *\n",
    "from preprocessing import *\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"num_head\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"dropout\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = read_csv_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = create_train_test_sample(text_data, GPT_CONFIG_124M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Step 0 Train loss 9.813279151916504 Val loss 9.931821823120117\n",
      "Epoch 0 Step 5 Train loss 8.098200162251791 Val loss 8.310367584228516\n",
      "who had lingered to give a lump of sugar , the, the,\n",
      "Epoch 1 Step 10 Train loss 6.718922932942708 Val loss 7.0871076583862305\n",
      "Epoch 1 Step 15 Train loss 6.066623051961263 Val loss 6.572519302368164\n",
      "who had lingered to give a lump of sugar , and, and,\n",
      "Epoch 2 Step 20 Train loss 5.601178010304769 Val loss 6.505828857421875\n",
      "Epoch 2 Step 25 Train loss 5.344935999976264 Val loss 6.424862384796143\n",
      "who had lingered to give a lump of sugar 's a him. \n",
      "Epoch 3 Step 30 Train loss 5.0728743341234 Val loss 6.447240829467773\n",
      "Epoch 3 Step 35 Train loss 4.622539467281765 Val loss 6.275482177734375\n",
      "who had lingered to give a lump of sugar . \"I had\n",
      "Epoch 4 Step 40 Train loss 4.192505439122518 Val loss 6.169416904449463\n",
      "who had lingered to give a lump of sugar .    \n",
      "Epoch 5 Step 45 Train loss 3.8267655902438693 Val loss 6.2545061111450195\n",
      "Epoch 5 Step 50 Train loss 3.436732954449124 Val loss 6.23394250869751\n",
      "who had lingered to give a lump of sugar .    \n",
      "Epoch 6 Step 55 Train loss 3.0542251004113092 Val loss 6.2152628898620605\n",
      "Epoch 6 Step 60 Train loss 2.6115727689531116 Val loss 6.131731033325195\n",
      "who had lingered to give a lump of sugar  he was not the fact\n",
      "Epoch 7 Step 65 Train loss 2.227377083566454 Val loss 6.104265213012695\n",
      "Epoch 7 Step 70 Train loss 1.8880027797487047 Val loss 6.116233825683594\n",
      "who had lingered to give a lump of sugar .    \n",
      "Epoch 8 Step 75 Train loss 1.5251040591133966 Val loss 6.174923896789551\n",
      "Epoch 8 Step 80 Train loss 1.2381845778889127 Val loss 6.180884838104248\n",
      "who had lingered to give a lump of sugar  he was \"interesting\":\n",
      "Epoch 9 Step 85 Train loss 0.9841181370947096 Val loss 6.220088958740234\n",
      "who had lingered to give a lump of sugar  he was \"interesting\":\n",
      "CPU times: user 19.5 s, sys: 2.88 s, total: 22.4 s\n",
      "Wall time: 54.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(123)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    eval_freq=5, eval_iter=5,\n",
    "    start_context=\"who had lingered to give a lump of sugar \", num_epochs=num_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " who had lingered to give a lump of sugar u.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\"I turned back to my work, and went on groping and muddling; then\n"
     ]
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "            model=model,\n",
    "            idx=text_to_token_ids(\"who had lingered to give a lump of sugar u\", tokenizer),\n",
    "            max_new_tokens=25,\n",
    "            context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    "            )\n",
    "print(\"Output text:\\n\", token_to_text(token_ids, tokenizer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
