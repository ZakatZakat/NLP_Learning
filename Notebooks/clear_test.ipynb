{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tiktoken'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtiktoken\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tiktoken'"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "sys.path.append('/Users/askarembulatov/Github_projects/NLP_task/NLP/NLP_Learning')\n",
    "\n",
    "from module import *\n",
    "from functions import *\n",
    "from dataloader import *\n",
    "from preprocessing import *\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"num_head\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"dropout\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = read_csv_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = create_train_test_sample(text_data, GPT_CONFIG_124M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Step 0 Train loss 9.812215699089897 Val loss 9.924274444580078\n",
      "Epoch 0 Step 5 Train loss 8.092656400468615 Val loss 8.30355453491211\n",
      "Every effort moves you, the, the,\n",
      "Epoch 1 Step 10 Train loss 6.7108720143636065 Val loss 7.074471473693848\n",
      "Epoch 1 Step 15 Train loss 6.06429926554362 Val loss 6.566693305969238\n",
      "Every effort moves you, and, and,\n",
      "Epoch 2 Step 20 Train loss 5.811701244778103 Val loss 6.538724899291992\n",
      "Epoch 2 Step 25 Train loss 4.9643246862623425 Val loss 6.310605525970459\n",
      "Every effort moves youSUPSUPSUPSUP \n",
      "Epoch 3 Step 30 Train loss 4.804154449039036 Val loss 6.32169246673584\n",
      "Epoch 3 Step 35 Train loss 4.183735662036472 Val loss 6.226553440093994\n",
      "Every effort moves you of the, and in\n",
      "Epoch 4 Step 40 Train loss 3.6980810695224338 Val loss 6.162346839904785\n",
      "Every effort moves you know that, and in\n",
      "Epoch 5 Step 45 Train loss 3.227117273542616 Val loss 6.206955432891846\n",
      "Epoch 5 Step 50 Train loss 2.756786929236518 Val loss 6.208232879638672\n",
      "Every effort moves you know that Mrs. \n",
      "Epoch 6 Step 55 Train loss 2.2751272122065225 Val loss 6.167365550994873\n",
      "Epoch 6 Step 60 Train loss 1.8652441766526964 Val loss 6.182987689971924\n",
      "Every effort moves you know,\" she had been\n",
      "Epoch 7 Step 65 Train loss 1.468769821855757 Val loss 6.239818096160889\n",
      "Epoch 7 Step 70 Train loss 1.17702712615331 Val loss 6.249002456665039\n",
      "Every effort moves you know,\" was one of\n",
      "Epoch 8 Step 75 Train loss 0.8518552581469218 Val loss 6.314907073974609\n",
      "Epoch 8 Step 80 Train loss 0.6241991784837511 Val loss 6.32651948928833\n",
      "Every effort moves you?\"    \n",
      "Epoch 9 Step 85 Train loss 0.4557180239094628 Val loss 6.390308380126953\n",
      "Every effort moves you?\"  \"Yes\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(123)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", num_epochs=num_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "            model=model,\n",
    "            idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "            max_new_tokens=25,\n",
    "            context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    "            )\n",
    "print(\"Output text:\\n\", token_to_text(token_ids, tokenizer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
